// backend/services/ai.service.js
const { GoogleGenerativeAI } = require("@google/generative-ai");

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);

const SYSTEM_INSTRUCTION = `
ROLE: Professional HR Dispatcher for the Polish job market.
TASK: Parse job text into a FLAT JSON structure in UKRAINIAN.

STRATEGY:
1. If the input text is a FULL description: Extract all details and translate to Ukrainian.
2. If the input text is a SHORT message (e.g., "Lisner, 10 women"): Fill the fields based on the context. 
3. AGENCY VS COMPANY: 
   - "agencyName" is ONLY for recruitment firms (e.g., EVL, OTTO, Gremi).
   - Factory names (Mondelez, Lisner, LG) MUST go into "description" or "title", NOT "agencyName".
   - If no agency mentioned, set "agencyName" to "Manual".

STRICT JSON STRUCTURE:
{
  "title": "Professional title in Ukrainian",
  "location": "City name (Polish name in brackets)",
  "agencyName": "Agency name or 'Manual'",
  "salary": {
    "base": "Base rate info in Ukrainian",
    "student": "Student rate info in Ukrainian",
    "bonus": "Bonuses info"
  },
  "schedule": "Working hours info in Ukrainian",
  "description": "Full job description/duties in Ukrainian",
  "accommodation": {
    "cost": "Cost info",
    "details": "Housing info"
  },
  "transport": "Transport info as a string",
  "requirements": {
    "gender": "Gender",
    "age": "Age",
    "docs": ["Doc1", "Doc2"]
  }
}

IMPORTANT: Return ONLY valid JSON, no markdown, no explanations.
`;

async function parseVacancyWithAI(rawText) {
  try {
    console.log(`ü§ñ –í—ã–∫–∞—Ä—ã—Å—Ç–∞–Ω–Ω–µ Gemini 2.5 Flash –¥–ª—è –ø–∞—Ä—Å—ñ–Ω–≥—É...`);
    
    const model = genAI.getGenerativeModel({ 
      model: "gemini-2.5-flash",
      generationConfig: {
        temperature: 0.2,        // –ú–µ–Ω–µ–π –∫—Ä—ç–∞—Ç—ã—û–Ω–∞—Å—Ü—ñ
        topP: 0.8,
        topK: 40,
        maxOutputTokens: 2048,
        responseMimeType: "application/json"  // –í–∞–∂–Ω–∞: –ø—Ä—ã–º—É—à–∞–µ –≤—è—Ä—Ç–∞—Ü—å JSON
      }
    });

    const prompt = `${SYSTEM_INSTRUCTION}\n\nInput text:\n${rawText}`;
    
    const result = await model.generateContent(prompt);
    const text = result.response.text();
    
    // –ê—á—ã—Å—Ç–∫–∞ JSON –∞–¥ –º–∞–≥—á—ã–º—ã—Ö markdown —Ç—ç–≥–∞—û
    let cleanJson = text.trim();
    cleanJson = cleanJson.replace(/```json\s*/g, "").replace(/```\s*/g, "");
    
    // –ó–Ω–∞—Ö–æ–¥–∑—ñ–º JSON –∞–±'–µ–∫—Ç, –Ω–∞–≤–∞—Ç –∫–∞–ª—ñ —ë—Å—Ü—å –ª—ñ—à–Ω—ñ —Ç—ç–∫—Å—Ç
    const jsonMatch = cleanJson.match(/\{[\s\S]*\}/);
    if (jsonMatch) {
      cleanJson = jsonMatch[0];
    }
    
    const parsed = JSON.parse(cleanJson);
    console.log(`‚úÖ –ü–∞—Ä—Å—ñ–Ω–≥ –ø–∞—Å–ø—è—Ö–æ–≤—ã`);
    
    return parsed;
    
  } catch (error) {
    // –ê–ø—Ä–∞—Ü–æ—û–∫–∞ rate limit
    if (error.message?.includes("429") || error.status === 429) {
      console.error("‚è±Ô∏è Rate limit: –∑–∞–Ω–∞–¥—Ç–∞ —à–º–∞—Ç –∑–∞–ø—ã—Ç–∞—û");
      throw new Error("RATE_LIMIT");
    }
    
    // –ê–ø—Ä–∞—Ü–æ—û–∫–∞ –ø–∞–º—ã–ª–∞–∫ –ø–∞—Ä—Å—ñ–Ω–≥—É JSON
    if (error instanceof SyntaxError) {
      console.error("‚ùå –ü–∞–º—ã–ª–∫–∞ –ø–∞—Ä—Å—ñ–Ω–≥—É JSON:", error.message);
      throw new Error("INVALID_JSON_RESPONSE");
    }
    
    console.error("‚ùå AI Service Error:", error.message);
    throw error;
  }
}

// –§—É–Ω–∫—Ü—ã—è –¥–ª—è —Ç—ç—Å—Ç–∞–≤–∞–Ω–Ω—è –∑–ª—É—á—ç–Ω–Ω—è
async function testConnection() {
  try {
    console.log("üîç –ü—Ä–∞–≤–µ—Ä–∫–∞ Gemini API...");
    const model = genAI.getGenerativeModel({ model: "gemini-2.5-flash" });
    await model.generateContent("Test connection");
    console.log("‚úÖ Gemini 2.5 Flash –¥–∞—Å—Ç—É–ø–Ω—ã");
    return true;
  } catch (error) {
    console.error("‚ùå Gemini API –Ω–µ–¥–∞—Å—Ç—É–ø–Ω—ã:", error.message);
    return false;
  }
}

// –§—É–Ω–∫—Ü—ã—è –¥–ª—è –∞—Ç—Ä—ã–º–∞–Ω–Ω—è —ñ–Ω—Ñ–∞—Ä–º–∞—Ü—ã—ñ –ø—Ä–∞ –≤—ã–∫–∞—Ä—ã—Å—Ç–∞–Ω–Ω–µ API
async function getModelInfo() {
  return {
    model: "gemini-2.5-flash",
    provider: "Google Generative AI",
    features: ["JSON parsing", "Ukrainian translation", "Context understanding"]
  };
}

module.exports = { 
  parseVacancyWithAI, 
  testConnection,
  getModelInfo
};